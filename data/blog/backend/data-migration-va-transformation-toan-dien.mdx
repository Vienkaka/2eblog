---
title: 'Migrations | 6. Data Migration và Transformation - Hướng dẫn toàn diện'
thumnail: 'https://fastly.picsum.photos/id/688/4608/3072.jpg?hmac=qIpK7qUXym0mfdFosdvte_Ia2COVGw9-WjBicJ3eSHg'
date: '2025-10-23T10:00:00Z'
lastmod: '2025-10-23T10:00:00Z'
tags: ['database', 'migration', 'data-transformation', 'backend', 'etl', 'data-migration']
draft: false
summary: 'Hướng dẫn toàn diện về data migration và transformation, bao gồm các kỹ thuật, best practices và case study thực tế cho E-Commerce Platform.'
images:
  [
    'https://fastly.picsum.photos/id/688/4608/3072.jpg?hmac=qIpK7qUXym0mfdFosdvte_Ia2COVGw9-WjBicJ3eSHg',
  ]
authors: ['default']
layout: PostLayout
canonicalUrl: https://gaoden.vercel.app/blog/backend/data-migration-va-transformation-toan-dien
---

## Giới thiệu

Data migration và transformation là những quá trình quan trọng trong quản lý database, cho phép schema evolution trong khi vẫn đảm bảo data integrity. Chúng không chỉ đơn giản là thay đổi schema mà còn liên quan đến việc thay đổi dữ liệu để phù hợp với cấu trúc mới hoặc đáp ứng các yêu cầu ứng dụng đang phát triển.

## Data Migration và Transformation là gì?

### Data Migration

**Data migration** là quá trình di chuyển dữ liệu từ một vị trí này sang vị trí khác, thường đi kèm với việc thay đổi schema.

### Data Transformation

**Data transformation** là quá trình thay đổi format, cấu trúc hoặc giá trị của dữ liệu để đáp ứng các yêu cầu mới.

Hai quá trình này thường được kết hợp với nhau, đặc biệt khi migrate sang hệ thống database khác hoặc thay đổi đáng kể schema hiện tại.

## Các loại Data Transformations

### 1. **Structural Transformations**

Thay đổi cấu trúc của dữ liệu:

```sql
-- Ví dụ: Split một cột thành nhiều cột
-- Trước: full_name VARCHAR(100)
-- Sau: first_name VARCHAR(50), last_name VARCHAR(50)

ALTER TABLE users ADD COLUMN first_name VARCHAR(50);
ALTER TABLE users ADD COLUMN last_name VARCHAR(50);

-- Split dữ liệu
UPDATE users
SET first_name = SPLIT_PART(full_name, ' ', 1),
    last_name = SPLIT_PART(full_name, ' ', 2);

-- Xóa cột cũ
ALTER TABLE users DROP COLUMN full_name;
```

### 2. **Data Type Transformations**

Chuyển đổi kiểu dữ liệu:

```sql
-- Chuyển đổi phone_number từ VARCHAR sang BIGINT
ALTER TABLE customers
ALTER COLUMN phone_number TYPE BIGINT
USING phone_number::BIGINT;

-- Chuyển đổi date string sang DATE type
ALTER TABLE orders
ALTER COLUMN order_date TYPE DATE
USING order_date::DATE;
```

### 3. **Value Transformations**

Thay đổi giá trị của dữ liệu:

```sql
-- Tính toán giá trị mới
UPDATE products
SET discounted_price = price * 0.9
WHERE category_id = 1;

-- Lookup từ bảng khác
UPDATE orders
SET customer_region = customers.region
FROM customers
WHERE orders.customer_id = customers.id;
```

### 4. **Data Cleansing**

Làm sạch dữ liệu:

```sql
-- Loại bỏ duplicates
DELETE FROM users
WHERE id NOT IN (
    SELECT MIN(id)
    FROM users
    GROUP BY email
);

-- Standardize phone numbers
UPDATE customers
SET phone = REGEXP_REPLACE(phone, '[^0-9]', '', 'g')
WHERE phone IS NOT NULL;
```

### 5. **Data Enrichment**

Bổ sung thông tin mới:

```sql
-- Thêm thông tin địa lý
UPDATE customers
SET country = geocoding.country,
    latitude = geocoding.latitude,
    longitude = geocoding.longitude
FROM geocoding
WHERE customers.address = geocoding.address;
```

## Key Considerations cho Data Migration

### 1. **Data Integrity**

Đảm bảo dữ liệu chính xác và nhất quán:

```sql
-- Validate data trước migration
SELECT COUNT(*) FROM products WHERE price < 0;
-- Should return 0

-- Validate sau migration
SELECT COUNT(*) FROM products WHERE discounted_price < 0;
-- Should return 0
```

### 2. **Downtime Minimization**

Giảm thiểu thời gian downtime:

```sql
-- Sử dụng online schema changes
ALTER TABLE products
ADD COLUMN new_field VARCHAR(100),
ALGORITHM=INPLACE, LOCK=NONE;
```

### 3. **Performance Optimization**

Tối ưu hóa quá trình migration:

```sql
-- Batch processing cho large datasets
UPDATE products
SET category_name = categories.name
FROM categories
WHERE products.category_id = categories.id
AND products.id BETWEEN 1 AND 10000;
```

### 4. **Reversibility**

Thiết kế migration có thể rollback:

```python
# Migration script với rollback capability
def upgrade():
    # Forward migration
    pass

def downgrade():
    # Backward migration
    pass
```

### 5. **Testing**

Test kỹ lưỡng trước khi deploy:

```python
def test_data_migration():
    # Test migration
    run_migration()

    # Verify data integrity
    assert data_integrity_check()

    # Test rollback
    rollback_migration()
    assert original_state_restored()
```

## Kỹ thuật Data Migration và Transformation

### 1. **Direct Data Manipulation**

Sử dụng SQL queries trực tiếp:

```sql
-- Thay đổi data type
ALTER TABLE customers
ALTER COLUMN phone_number TYPE BIGINT
USING phone_number::BIGINT;

-- Split column
ALTER TABLE users ADD COLUMN first_name VARCHAR(50);
ALTER TABLE users ADD COLUMN last_name VARCHAR(50);

UPDATE users
SET first_name = SPLIT_PART(full_name, ' ', 1),
    last_name = SPLIT_PART(full_name, ' ', 2);

ALTER TABLE users DROP COLUMN full_name;
```

**Ưu điểm**: Đơn giản, nhanh chóng
**Nhược điểm**: Khó track changes, rủi ro cao với large datasets

### 2. **ETL Tools**

Sử dụng các công cụ ETL chuyên nghiệp:

```yaml
# Apache NiFi example
- name: ExtractData
  type: ExecuteSQL
  sql: 'SELECT * FROM legacy_products'

- name: TransformData
  type: JoltTransformJSON
  spec: |
    [
      {
        "operation": "shift",
        "spec": {
          "name": "product_name",
          "price": "product_price"
        }
      }
    ]

- name: LoadData
  type: PutDatabaseRecord
  table: 'products'
```

**Ưu điểm**: Structured framework, data profiling, quality checks
**Nhược điểm**: Phức tạp setup, learning curve

### 3. **Programming Languages và Scripts**

Sử dụng Python, Ruby, Java:

```python
import sqlite3
import hashlib

def migrate_user_data():
    conn = sqlite3.connect('ecommerce.db')
    cursor = conn.cursor()

    # Add new columns
    cursor.execute("ALTER TABLE users ADD COLUMN first_name TEXT")
    cursor.execute("ALTER TABLE users ADD COLUMN last_name TEXT")
    cursor.execute("ALTER TABLE users ADD COLUMN email_hash TEXT")

    # Fetch existing data
    cursor.execute("SELECT id, full_name, email FROM users")
    users = cursor.fetchall()

    for user_id, full_name, email in users:
        try:
            # Split full name
            first_name, last_name = full_name.split(' ', 1)
        except ValueError:
            first_name = full_name
            last_name = ''

        # Hash email for privacy
        email_hash = hashlib.sha256(email.encode()).hexdigest()

        # Update user record
        cursor.execute("""
            UPDATE users
            SET first_name = ?, last_name = ?, email_hash = ?
            WHERE id = ?
        """, (first_name, last_name, email_hash, user_id))

    # Remove old columns
    cursor.execute("ALTER TABLE users DROP COLUMN full_name")
    cursor.execute("ALTER TABLE users DROP COLUMN email")

    conn.commit()
    conn.close()
```

**Ưu điểm**: Flexibility cao, fine-grained control
**Nhược điểm**: Cần development effort, maintenance overhead

### 4. **Database-Specific Features**

Sử dụng tính năng built-in của database:

```sql
-- PostgreSQL COPY command
COPY products FROM '/path/to/products.csv'
WITH (FORMAT CSV, HEADER);

-- MySQL LOAD DATA
LOAD DATA INFILE '/path/to/products.csv'
INTO TABLE products
FIELDS TERMINATED BY ','
ENCLOSED BY '"'
LINES TERMINATED BY '\n'
IGNORE 1 ROWS;

-- Bulk insert với transaction
BEGIN;
INSERT INTO products (name, price, category_id) VALUES
('Product 1', 10.99, 1),
('Product 2', 20.99, 2),
('Product 3', 30.99, 1);
COMMIT;
```

**Ưu điểm**: Optimized performance, handle large datasets
**Nhược điểm**: Database-specific, limited flexibility

## Handling Complex Schema Changes

### 1. **Incremental Migrations**

Chia nhỏ complex changes:

```python
# Migration 1: Add new columns
def upgrade():
    op.add_column('products', sa.Column('product_type', sa.String(50)))
    op.add_column('products', sa.Column('digital_download_url', sa.String(255)))

# Migration 2: Populate data
def upgrade():
    op.execute("""
        UPDATE products
        SET product_type = 'digital'
        WHERE name LIKE '%ebook%' OR description LIKE '%digital%'
    """)

# Migration 3: Add constraints
def upgrade():
    op.alter_column('products', 'product_type', nullable=False)
```

### 2. **Feature Flags**

Deploy schema changes với feature flags:

```python
# Migration với feature flag
def upgrade():
    # Add new columns
    op.add_column('products', sa.Column('new_feature_data', sa.JSON))

    # Add feature flag
    op.execute("""
        INSERT INTO feature_flags (name, enabled, description)
        VALUES ('new_product_features', false, 'New product features')
    """)

# Application code
def get_product_data(product_id):
    if feature_flags.is_enabled('new_product_features'):
        return get_enhanced_product_data(product_id)
    else:
        return get_legacy_product_data(product_id)
```

### 3. **Data Backfilling**

Backfill existing data:

```sql
-- Backfill country data
UPDATE customers
SET country = addresses.country
FROM addresses
WHERE customers.address_id = addresses.id;

-- Backfill calculated fields
UPDATE products
SET total_sales = (
    SELECT COALESCE(SUM(quantity), 0)
    FROM order_items
    WHERE order_items.product_id = products.id
);
```

### 4. **Data Archiving**

Archive old data trước khi migrate:

```sql
-- Archive old orders
INSERT INTO orders_archive
SELECT * FROM orders
WHERE order_date < '2020-01-01';

-- Delete archived data
DELETE FROM orders
WHERE order_date < '2020-01-01';
```

### 5. **Schema Versioning**

Track schema changes:

```sql
-- Schema version table
CREATE TABLE schema_versions (
    version VARCHAR(50) PRIMARY KEY,
    applied_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    description TEXT
);

-- Track migration
INSERT INTO schema_versions (version, description)
VALUES ('001_add_product_types', 'Add product type categorization');
```

## Case Study: E-Commerce Platform Data Migration

### Scenario: Thêm Product Type Classification

Giả sử chúng ta cần thêm cột `product_type` vào bảng `products` để phân loại sản phẩm thành "physical", "digital", hoặc "service".

```python
import sqlite3
import re

def migrate_product_types():
    conn = sqlite3.connect('ecommerce.db')
    cursor = conn.cursor()

    # Add product_type column
    cursor.execute("""
        ALTER TABLE products
        ADD COLUMN product_type TEXT DEFAULT 'physical'
    """)

    # Backfill based on product names/descriptions
    cursor.execute("""
        UPDATE products
        SET product_type = 'digital'
        WHERE name LIKE '%ebook%'
           OR name LIKE '%digital%'
           OR description LIKE '%download%'
           OR description LIKE '%software%'
    """)

    cursor.execute("""
        UPDATE products
        SET product_type = 'service'
        WHERE name LIKE '%consulting%'
           OR name LIKE '%service%'
           OR description LIKE '%consulting%'
           OR description LIKE '%support%'
    """)

    # Verify changes
    cursor.execute("""
        SELECT id, name, product_type, COUNT(*) as count
        FROM products
        GROUP BY product_type
    """)

    results = cursor.fetchall()
    for product_type, count in results:
        print(f"Product Type: {product_type}, Count: {count}")

    conn.commit()
    conn.close()

# Advanced classification với ML
def classify_products_with_ml():
    import pandas as pd
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.cluster import KMeans

    # Load data
    df = pd.read_sql("SELECT id, name, description FROM products", conn)

    # Feature extraction
    vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')
    X = vectorizer.fit_transform(df['name'] + ' ' + df['description'])

    # Clustering
    kmeans = KMeans(n_clusters=3, random_state=42)
    clusters = kmeans.fit_predict(X)

    # Map clusters to product types
    cluster_mapping = {
        0: 'physical',
        1: 'digital',
        2: 'service'
    }

    # Update database
    for idx, cluster in enumerate(clusters):
        product_type = cluster_mapping[cluster]
        cursor.execute("""
            UPDATE products
            SET product_type = ?
            WHERE id = ?
        """, (product_type, df.iloc[idx]['id']))
```

## Advanced Data Transformation Techniques

### 1. **Data Validation và Quality Checks**

```python
def validate_migration():
    conn = sqlite3.connect('ecommerce.db')
    cursor = conn.cursor()

    # Check data integrity
    checks = [
        ("No negative prices", "SELECT COUNT(*) FROM products WHERE price < 0"),
        ("No empty product names", "SELECT COUNT(*) FROM products WHERE name IS NULL OR name = ''"),
        ("Valid product types", "SELECT COUNT(*) FROM products WHERE product_type NOT IN ('physical', 'digital', 'service')"),
        ("No orphaned order items", "SELECT COUNT(*) FROM order_items oi LEFT JOIN products p ON oi.product_id = p.id WHERE p.id IS NULL")
    ]

    for check_name, query in checks:
        cursor.execute(query)
        count = cursor.fetchone()[0]
        if count > 0:
            print(f"❌ {check_name}: {count} violations found")
        else:
            print(f"✅ {check_name}: No violations")

    conn.close()
```

### 2. **Performance Optimization**

```python
def optimized_migration():
    conn = sqlite3.connect('ecommerce.db')
    cursor = conn.cursor()

    # Batch processing
    batch_size = 1000
    offset = 0

    while True:
        cursor.execute("""
            SELECT id, name, description
            FROM products
            LIMIT ? OFFSET ?
        """, (batch_size, offset))

        batch = cursor.fetchall()
        if not batch:
            break

        # Process batch
        for product_id, name, description in batch:
            product_type = classify_product(name, description)
            cursor.execute("""
                UPDATE products
                SET product_type = ?
                WHERE id = ?
            """, (product_type, product_id))

        offset += batch_size
        print(f"Processed {offset} products...")

    conn.commit()
    conn.close()

def classify_product(name, description):
    """Simple classification logic"""
    text = (name + ' ' + description).lower()

    if any(keyword in text for keyword in ['ebook', 'digital', 'download', 'software']):
        return 'digital'
    elif any(keyword in text for keyword in ['consulting', 'service', 'support', 'training']):
        return 'service'
    else:
        return 'physical'
```

### 3. **Error Handling và Recovery**

```python
def robust_migration():
    conn = sqlite3.connect('ecommerce.db')
    cursor = conn.cursor()

    try:
        # Start transaction
        cursor.execute("BEGIN")

        # Create backup table
        cursor.execute("""
            CREATE TABLE products_backup AS
            SELECT * FROM products
        """)

        # Perform migration
        cursor.execute("ALTER TABLE products ADD COLUMN product_type TEXT")

        # Update with error handling
        cursor.execute("SELECT id, name, description FROM products")
        products = cursor.fetchall()

        for product_id, name, description in products:
            try:
                product_type = classify_product(name, description)
                cursor.execute("""
                    UPDATE products
                    SET product_type = ?
                    WHERE id = ?
                """, (product_type, product_id))
            except Exception as e:
                print(f"Error processing product {product_id}: {e}")
                # Continue with next product

        # Commit changes
        cursor.execute("COMMIT")
        print("Migration completed successfully")

    except Exception as e:
        print(f"Migration failed: {e}")
        cursor.execute("ROLLBACK")

        # Restore from backup
        cursor.execute("DROP TABLE products")
        cursor.execute("ALTER TABLE products_backup RENAME TO products")
        print("Database restored from backup")

    finally:
        conn.close()
```

## Exercises thực hành

### 1. **Splitting Address Data**

```python
def split_address_data():
    conn = sqlite3.connect('ecommerce.db')
    cursor = conn.cursor()

    # Add new columns
    cursor.execute("ALTER TABLE customers ADD COLUMN street TEXT")
    cursor.execute("ALTER TABLE customers ADD COLUMN city TEXT")
    cursor.execute("ALTER TABLE customers ADD COLUMN state TEXT")
    cursor.execute("ALTER TABLE customers ADD COLUMN zip_code TEXT")

    # Fetch addresses
    cursor.execute("SELECT id, address FROM customers WHERE address IS NOT NULL")
    customers = cursor.fetchall()

    for customer_id, address in customers:
        try:
            # Parse address: "123 Main St, Anytown, CA 91234"
            parts = [part.strip() for part in address.split(',')]

            if len(parts) >= 3:
                street = parts[0]
                city = parts[1]
                state_zip = parts[2].split()

                if len(state_zip) >= 2:
                    state = state_zip[0]
                    zip_code = state_zip[1]
                else:
                    state = state_zip[0]
                    zip_code = None
            else:
                street = address
                city = None
                state = None
                zip_code = None

            # Update customer record
            cursor.execute("""
                UPDATE customers
                SET street = ?, city = ?, state = ?, zip_code = ?
                WHERE id = ?
            """, (street, city, state, zip_code, customer_id))

        except Exception as e:
            print(f"Error parsing address for customer {customer_id}: {e}")

    conn.commit()
    conn.close()
```

### 2. **Standardizing Date Formats**

```python
from datetime import datetime
import re

def standardize_date_formats():
    conn = sqlite3.connect('ecommerce.db')
    cursor = conn.cursor()

    # Add new standardized date column
    cursor.execute("ALTER TABLE orders ADD COLUMN order_date_standardized DATE")

    # Fetch dates
    cursor.execute("SELECT id, order_date FROM orders WHERE order_date IS NOT NULL")
    orders = cursor.fetchall()

    for order_id, order_date in orders:
        try:
            # Parse different date formats
            standardized_date = parse_date(order_date)

            if standardized_date:
                cursor.execute("""
                    UPDATE orders
                    SET order_date_standardized = ?
                    WHERE id = ?
                """, (standardized_date, order_id))

        except Exception as e:
            print(f"Error parsing date for order {order_id}: {e}")

    conn.commit()
    conn.close()

def parse_date(date_string):
    """Parse various date formats to YYYY-MM-DD"""
    date_string = str(date_string).strip()

    # Try different formats
    formats = [
        '%Y-%m-%d',      # YYYY-MM-DD
        '%m/%d/%Y',      # MM/DD/YYYY
        '%d-%m-%Y',      # DD-MM-YYYY
        '%Y/%m/%d',      # YYYY/MM/DD
        '%d/%m/%Y',      # DD/MM/YYYY
    ]

    for fmt in formats:
        try:
            return datetime.strptime(date_string, fmt).strftime('%Y-%m-%d')
        except ValueError:
            continue

    return None
```

### 3. **Converting Currency Values**

```python
def convert_currency_to_usd():
    conn = sqlite3.connect('ecommerce.db')
    cursor = conn.cursor()

    # Create exchange rates table
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS exchange_rates (
            currency_code VARCHAR(3) PRIMARY KEY,
            exchange_rate DECIMAL(10, 4)
        )
    """)

    # Insert exchange rates
    exchange_rates = [
        ('USD', 1.0),
        ('EUR', 0.85),
        ('GBP', 0.73),
        ('JPY', 110.0),
        ('CAD', 1.25)
    ]

    cursor.executemany("""
        INSERT OR REPLACE INTO exchange_rates (currency_code, exchange_rate)
        VALUES (?, ?)
    """, exchange_rates)

    # Add USD price column
    cursor.execute("ALTER TABLE products ADD COLUMN price_usd DECIMAL(10, 2)")

    # Convert prices
    cursor.execute("""
        UPDATE products
        SET price_usd = price * er.exchange_rate
        FROM exchange_rates er
        WHERE products.currency = er.currency_code
    """)

    conn.commit()
    conn.close()
```

### 4. **Data Masking cho Privacy**

```python
import hashlib
import base64

def mask_sensitive_data():
    conn = sqlite3.connect('ecommerce.db')
    cursor = conn.cursor()

    # Add masked columns
    cursor.execute("ALTER TABLE users ADD COLUMN email_masked TEXT")
    cursor.execute("ALTER TABLE users ADD COLUMN phone_masked TEXT")

    # Fetch sensitive data
    cursor.execute("SELECT id, email, phone FROM users")
    users = cursor.fetchall()

    for user_id, email, phone in users:
        # Hash email
        email_hash = hashlib.sha256(email.encode()).hexdigest()[:16]
        email_masked = f"{email_hash}@masked.com"

        # Mask phone number
        if phone:
            phone_masked = f"***-***-{phone[-4:]}" if len(phone) >= 4 else "***-***-****"
        else:
            phone_masked = None

        # Update user record
        cursor.execute("""
            UPDATE users
            SET email_masked = ?, phone_masked = ?
            WHERE id = ?
        """, (email_masked, phone_masked, user_id))

    conn.commit()
    conn.close()
```

## Best Practices Summary

### 1. **Planning và Preparation**

- Backup data trước khi migration
- Test trên staging environment
- Plan rollback strategy
- Document migration process

### 2. **Data Validation**

- Validate data trước và sau migration
- Check data integrity constraints
- Verify business rules
- Monitor data quality metrics

### 3. **Performance Optimization**

- Use batch processing cho large datasets
- Optimize database queries
- Monitor resource usage
- Consider parallel processing

### 4. **Error Handling**

- Implement comprehensive error handling
- Log all operations
- Provide rollback mechanisms
- Monitor migration progress

### 5. **Testing**

- Unit test migration scripts
- Integration test với real data
- Performance test với large datasets
- User acceptance testing

## Kết luận

Data migration và transformation là những kỹ năng quan trọng cho backend developers. Việc hiểu và áp dụng đúng các kỹ thuật sẽ giúp:

- **Đảm bảo data integrity** trong quá trình migration
- **Tối ưu hóa performance** và giảm downtime
- **Xử lý complex schema changes** một cách an toàn
- **Maintain data quality** và consistency

Những kiến thức trong bài viết này sẽ giúp bạn xây dựng một data migration strategy vững chắc cho dự án của mình.

Bạn có kinh nghiệm gì về data migration và transformation không? Hãy chia sẻ trong phần comment nhé!

## Tài liệu tham khảo

- [Database Migration Best Practices](https://www.postgresql.org/docs/current/ddl-alter.html)
- [ETL Tools Comparison](https://www.guru99.com/etl-testing-tools.html)
- [Data Quality Management](https://www.talend.com/resources/what-is-data-quality/)
- [SQLAlchemy Migration Guide](https://alembic.sqlalchemy.org/)
- [Python Data Processing](https://pandas.pydata.org/docs/)
